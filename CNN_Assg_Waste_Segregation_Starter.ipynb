{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anushan1989/Waster_Segregation_CNN/blob/main/CNN_Assg_Waste_Segregation_Starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Waste Material Segregation for Improving Waste Management\n",
        "\n",
        "\n",
        "```\n",
        "Objective\n",
        "\n",
        "The objective of this project is to implement an effective waste material segregation system using convolutional neural networks (CNNs) that categorises waste into distinct groups. This process enhances recycling efficiency, minimises environmental pollution, and promotes sustainable waste management practices.\n",
        "\n",
        "The key goals are:\n",
        "\n",
        "    Accurately classify waste materials into categories like cardboard, glass, paper, and plastic.\n",
        "    Improve waste segregation efficiency to support recycling and reduce landfill waste.\n",
        "    Understand the properties of different waste materials to optimise sorting methods for sustainability.\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "a4YOL_I55tnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Understanding"
      ],
      "metadata": {
        "id": "F_0qr0Vl7FWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dataset consists of images of some common waste materials.\n",
        "\n",
        "    Food Waste\n",
        "    Metal\n",
        "    Paper\n",
        "    Plastic\n",
        "    Other\n",
        "    Cardboard\n",
        "    Glass\n"
      ],
      "metadata": {
        "id": "N4bVIA9m7M_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Data Description\n",
        "\n",
        "    The dataset consists of multiple folders, each representing a specific class, such as Cardboard, Food_Waste, and Metal.\n",
        "    Within each folder, there are images of objects that belong to that category.\n",
        "    However, these items are not further subcategorised.\n",
        "    For instance, the Food_Waste folder may contain images of items like coffee grounds, teabags, and fruit peels, without explicitly stating that they are actually coffee grounds or teabags.\n",
        "\n"
      ],
      "metadata": {
        "id": "Mm8iZM5e7QGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the data\n",
        "\n",
        "Load and unzip the dataset zip file.\n"
      ],
      "metadata": {
        "id": "TeAb34SU7XqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Necessary Libraries"
      ],
      "metadata": {
        "id": "z1WyueBh7c9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommended versions:\n",
        "\n",
        "# numpy version: 1.26.4\n",
        "# pandas version: 2.2.2\n",
        "# seaborn version: 0.13.2\n",
        "# matplotlib version: 3.10.0\n",
        "# PIL version: 11.1.0\n",
        "# tensorflow version: 2.18.0\n",
        "# keras version: 3.8.0\n",
        "# sklearn version: 1.6.1"
      ],
      "metadata": {
        "id": "MBIOL1jH7i0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "zZ2vWMV6tTPK",
        "outputId": "b861c79f-f15a-4b78-e678-de003690e000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.11.0.86\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGKThJ2W1KAX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os # Import the os module\n",
        "import cv2\n",
        "import sklearn\n",
        "from PIL import Image as im\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import zipfile # Import the zipfile module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0E0EzHb1hry"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "print(os.getcwd())\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK8zxQu216E8"
      },
      "outputs": [],
      "source": [
        "# Load and unzip the dataset\n",
        "# Assuming the dataset zip file is named 'waste_dataset.zip'\n",
        "# Uncomment the following lines when working with the actual zip file\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Colab_Notebooks/data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('Garbage_classification')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypk_BQ4E11W4"
      },
      "outputs": [],
      "source": [
        "# Path to the dataset directory\n",
        "#dataset_path = 'Garbage_classification/data/Paper'  # Update this path as needed\n",
        "import os\n",
        "data_path = '/content/Garbage_classification/data'\n",
        "os.listdir(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5UQQbkW4obU"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "img_height = 244\n",
        "img_width = 244"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpYr5HLt4fGf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'training',\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    seed = 123,\n",
        "    #Limit the number of training samples\n",
        "    #labels = ['0', '1', '2', '3', '4', '5'][:2000] #Limit the number of labels to 2000)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccuUC0Zh4_qi"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'validation',\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    seed = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXzV6X055H2K"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ucpDY9d38vO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(len(class_names)):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[i])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScOnuW3V5N-g"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    #layers.CenterCrop(125, 125),\n",
        "    layers.RandomFlip('horizontal', input_shape = (img_height, img_width, 3)),\n",
        "    layers.RandomRotation(0.2, fill_mode = 'nearest'),\n",
        "    layers.RandomZoom(0.1),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZH8p-TL5ebl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(len(class_names)):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "   # plt.title(class_names[2])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zJChC1S5lSB"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zRGmaVk5qIp"
      },
      "outputs": [],
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = (img_height, img_width, 3)\n",
        "base_model = tf.keras.applications.VGG16(input_shape = IMG_SHAPE,\n",
        "                                         include_top = False,\n",
        "                                         weights = 'imagenet')\n",
        "#base_model.trainable = False\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSbLpxq15sbk"
      },
      "outputs": [],
      "source": [
        "def print_layer_trainable():\n",
        "    for layer in base_model.layers:\n",
        "        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVkkRlGJ5xd2"
      },
      "outputs": [],
      "source": [
        "print_layer_trainable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCLmvuhI50vt"
      },
      "outputs": [],
      "source": [
        "# Unfreeze some layers of the base model\n",
        "#base_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGBB7ye-57Q7"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = False\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    if 'block5' in layer.name or 'block4' in layer.name:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHbozc1N2Y7s"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip('horizontal', input_shape = (img_height, img_width, 3)),\n",
        "    layers.RandomRotation(0.2, fill_mode = 'nearest'),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.2),  # Added random contrast adjustment\n",
        "    # Add more augmentation techniques as needed\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c6vWyW-5_uU"
      },
      "outputs": [],
      "source": [
        "n_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "    data_augmentation,\n",
        "    layers.Rescaling(1./255),\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(n_classes, activation = 'softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHXSAW986ECI"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQwS-vAU6GPv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yY36ng36KEg"
      },
      "outputs": [],
      "source": [
        "# Model Chackpoint\n",
        "tl_checkpoint_1 = ModelCheckpoint(filepath = 'vgg16_best_weights.hdf5.keras', save_best_only = True, verbose = 0)\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True, mode = 'min')\n",
        "\n",
        "# Import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# ReduceLROnPlateau\n",
        "rop_callback = ReduceLROnPlateau(monitor = 'val_loss', patience = 2,  # Reduced patience\n",
        "                                verbose = 1, factor = 0.5, min_lr = 0.000001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q21E-JG36hW7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "%%time\n",
        "history = model.fit(train_ds,\n",
        "                    epochs = 25,\n",
        "                    validation_data = val_ds,\n",
        "                    callbacks = [tl_checkpoint_1, early_stop, rop_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LeCNRxe_-1I"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = 1,\n",
        "    seed = 123)\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irVHB-239D6H"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(10)\n",
        "\n",
        "plt.figure(figsize = (10, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label = 'Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label = 'Validation Accuracy')\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label = 'Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label = 'Validation Loss')\n",
        "plt.legend(loc = 'upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = 1,\n",
        "    seed = 123)\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)"
      ],
      "metadata": {
        "id": "pu_fluHSkefA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RadmX1aEAT0D"
      },
      "outputs": [],
      "source": [
        "# Generate predictions\n",
        "model.load_weights('/content/vgg16_best_weights.hdf5.keras') # initialize the best trained weights\n",
        "preds = model.predict(test_ds)\n",
        "pred_classes = np.argmax(preds, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS82BggTCVYN"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_ds, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFzAUErlCaXV"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def print_layer_trainable(): # Defining the function 'print_layer_trainable'\n",
        "    for layer in base_model.layers:\n",
        "        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))\n",
        "\n",
        "IMG_SHAPE = (img_height, img_width, 3)\n",
        "base_model = tf.keras.applications.VGG16(input_shape = IMG_SHAPE,\n",
        "                                         include_top = False,\n",
        "                                         weights = 'imagenet')\n",
        "\n",
        "\n",
        "fine_tune  = base_model\n",
        "\n",
        "\n",
        "fine_tune.trainable = True\n",
        "\n",
        "\n",
        "for layer in fine_tune.layers:\n",
        "    # Boolean whether this layer is trainable.\n",
        "    trainable = ('block5' in layer.name or 'block4' in layer.name)\n",
        "\n",
        "    # Set the layer's bool.\n",
        "    layer.trainable = trainable\n",
        "\n",
        "\n",
        "print_layer_trainable()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YicgUlRCfLE"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "fine_tune.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CVrzOwWCjla"
      },
      "outputs": [],
      "source": [
        "n_classes = len(class_names)\n",
        "\n",
        "model2 = Sequential([\n",
        "    data_augmentation,\n",
        "    layers.Rescaling(1./255),\n",
        "    fine_tune,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(n_classes, activation = 'softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3mh8mIpClZ5"
      },
      "outputs": [],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgpmV6A_Co6x"
      },
      "outputs": [],
      "source": [
        "model2.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_4xQ8NPCvi9"
      },
      "outputs": [],
      "source": [
        "# Model Chackpoint\n",
        "tl_checkpoint_1 = ModelCheckpoint(filepath = 'vgg16_best_weights_fine_tuning.hdf5.keras', save_best_only = True, verbose = 0)\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights = True, mode = 'min')\n",
        "\n",
        "# Import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "#ReduceLROnPlateau to stabilize the training process of the model\n",
        "rop_callback = ReduceLROnPlateau(monitor = 'val_loss', patience = 3, verbose = 1, factor = 0.5, min_lr = 0.000001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61-qguV3Czge"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history = model2.fit(train_ds,\n",
        "                    epochs = 10,\n",
        "                    validation_data = val_ds,\n",
        "                    callbacks = [tl_checkpoint_1, early_stop, rop_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(10)\n",
        "\n",
        "plt.figure(figsize = (10, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label = 'Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label = 'Validation Accuracy')\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label = 'Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label = 'Validation Loss')\n",
        "plt.legend(loc = 'upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dXNjb-Oum5h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE # Define AUTOTUNE here using tf.data.AUTOTUNE\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = 1,\n",
        "    seed = 123)\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)"
      ],
      "metadata": {
        "id": "VrntFPrFnB5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "model2.load_weights('/content/vgg16_best_weights_fine_tuning.hdf5') # initialize the best trained weights\n",
        "preds = model2.predict(test_ds)\n",
        "pred_classes = np.argmax(preds, axis = 1)"
      ],
      "metadata": {
        "id": "LJ78uC3MnKw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(test_ds, verbose = 1)"
      ],
      "metadata": {
        "id": "wnQBcBS9nP1h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPJ3asghFH0vr7DzjB03Ns7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}